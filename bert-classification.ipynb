{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-31T16:28:51.516052Z",
     "iopub.status.busy": "2023-05-31T16:28:51.515643Z",
     "iopub.status.idle": "2023-05-31T16:29:05.299928Z",
     "shell.execute_reply": "2023-05-31T16:29:05.298758Z",
     "shell.execute_reply.started": "2023-05-31T16:28:51.516018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('../input/mbti-type/mbti_1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensorflow\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:05.302672Z",
     "iopub.status.busy": "2023-05-31T16:29:05.302289Z",
     "iopub.status.idle": "2023-05-31T16:29:10.630340Z",
     "shell.execute_reply": "2023-05-31T16:29:10.629386Z",
     "shell.execute_reply.started": "2023-05-31T16:29:05.302642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.0.0.2:8470']\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "#Check if TPU is available\n",
    "use_tpu = True\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data is extremely imbalanced.** This might cause overfitting to happen since the total data only amounts to 8675."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sklearn and plot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:12.463827Z",
     "iopub.status.busy": "2023-05-31T16:29:12.463382Z",
     "iopub.status.idle": "2023-05-31T16:29:12.484603Z",
     "shell.execute_reply": "2023-05-31T16:29:12.483515Z",
     "shell.execute_reply.started": "2023-05-31T16:29:12.463787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1832\n",
       "INFJ    1470\n",
       "INTP    1304\n",
       "INTJ    1091\n",
       "ENTP     685\n",
       "ENFP     675\n",
       "ISTP     337\n",
       "ISFP     271\n",
       "ENTJ     231\n",
       "ISTJ     205\n",
       "ENFJ     190\n",
       "ISFJ     166\n",
       "ESTP      89\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:12.486217Z",
     "iopub.status.busy": "2023-05-31T16:29:12.485861Z",
     "iopub.status.idle": "2023-05-31T16:29:12.500697Z",
     "shell.execute_reply": "2023-05-31T16:29:12.499399Z",
     "shell.execute_reply.started": "2023-05-31T16:29:12.486177Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def clean_text(data):\n",
    "    data_length=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    cleaned_text=[]\n",
    "    for sentence in tqdm(data.posts):\n",
    "        sentence=sentence.lower()\n",
    "        \n",
    "        #removing links from text data\n",
    "        sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n",
    "    \n",
    "        #removing other symbols\n",
    "        sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "    \n",
    "        \n",
    "        data_length.append(len(sentence.split()))\n",
    "        cleaned_text.append(sentence)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:12.502552Z",
     "iopub.status.busy": "2023-05-31T16:29:12.502116Z",
     "iopub.status.idle": "2023-05-31T16:29:24.521547Z",
     "shell.execute_reply": "2023-05-31T16:29:24.520385Z",
     "shell.execute_reply.started": "2023-05-31T16:29:12.502499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc77d12cd916421cb0ddac31866d0d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and intj moments     sportscenter not top t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i m finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one            course  to which i say i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    i enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you re fired    that s another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>just because i always think of cats as fi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>so   if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>so many questions when i do these things   i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>i am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>it has been too long since i have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ     and intj moments     sportscenter not top t...\n",
       "1     ENTP   i m finding the lack of me in these posts ver...\n",
       "2     INTP   good one            course  to which i say i ...\n",
       "3     INTJ   dear intp    i enjoyed our conversation the o...\n",
       "4     ENTJ   you re fired    that s another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP     just because i always think of cats as fi d...\n",
       "8671  ENFP   so   if this thread already exists someplace ...\n",
       "8672  INTP   so many questions when i do these things   i ...\n",
       "8673  INFP   i am very conflicted right now when it comes ...\n",
       "8674  INFP   it has been too long since i have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.posts = clean_text(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:24.523932Z",
     "iopub.status.busy": "2023-05-31T16:29:24.523476Z",
     "iopub.status.idle": "2023-05-31T16:29:24.542554Z",
     "shell.execute_reply": "2023-05-31T16:29:24.541320Z",
     "shell.execute_reply.started": "2023-05-31T16:29:24.523892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 1735)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "posts = data['posts'].values\n",
    "labels =  data['type'].values\n",
    "train_data, test_data = train_test_split(data, random_state=0, test_size=0.2)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:29:24.545864Z",
     "iopub.status.busy": "2023-05-31T16:29:24.544520Z",
     "iopub.status.idle": "2023-05-31T16:37:06.050414Z",
     "shell.execute_reply": "2023-05-31T16:37:06.049365Z",
     "shell.execute_reply.started": "2023-05-31T16:29:24.545822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc543ec48542bda9a47486c103b3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149e8ef37e5149b6ace7779fc258be68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9401fc1697644ad3a2f1977e3038e607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3d3f1f33b144a585cf3a79ca1cb145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6940 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac27b446d44aa2bd25f2d5b045325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize Bert tokenizer and masks\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "bert_model_name = 'bert-large-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)\n",
    "MAX_LEN = 512\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_seq_len = 1800):\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokenized_sentence = (\n",
    "                            sentence,                  # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_seq_len,  # Truncate all sentences.\n",
    "                    )\n",
    "        \n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "        \n",
    "    return tokenized_sentences\n",
    "\n",
    "def create_attention_masks(tokenized_and_padded_sentences):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in tokenized_and_padded_sentences:\n",
    "        att_mask = [int(token_id > 0) for token_id in sentence]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return np.asarray(attention_masks)\n",
    "\n",
    "train_input_ids = tokenize_sentences(train_data['posts'], tokenizer, MAX_LEN)\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "train_attention_masks = create_attention_masks(train_input_ids)\n",
    "\n",
    "test_input_ids = tokenize_sentences(test_data['posts'], tokenizer, MAX_LEN)\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "test_attention_masks = create_attention_masks(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:37:06.064734Z",
     "iopub.status.busy": "2023-05-31T16:37:06.064270Z",
     "iopub.status.idle": "2023-05-31T16:37:06.075548Z",
     "shell.execute_reply": "2023-05-31T16:37:06.074346Z",
     "shell.execute_reply.started": "2023-05-31T16:37:06.064703Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant\n",
    "BATCH_SIZE=64\n",
    "NR_EPOCHS=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:37:06.097405Z",
     "iopub.status.busy": "2023-05-31T16:37:06.096644Z",
     "iopub.status.idle": "2023-05-31T16:37:06.113337Z",
     "shell.execute_reply": "2023-05-31T16:37:06.112093Z",
     "shell.execute_reply.started": "2023-05-31T16:37:06.097375Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define f1 functions for evaluation\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:37:06.116166Z",
     "iopub.status.busy": "2023-05-31T16:37:06.115160Z",
     "iopub.status.idle": "2023-05-31T16:37:06.130128Z",
     "shell.execute_reply": "2023-05-31T16:37:06.129193Z",
     "shell.execute_reply.started": "2023-05-31T16:37:06.116125Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERT model\n",
    "def create_model(): \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32,\n",
    "                                           name=\"input_word_ids\")\n",
    "    bert_layer = transformers.TFBertModel.from_pretrained('bert-large-uncased')\n",
    "    bert_outputs = bert_layer(input_word_ids)[0]\n",
    "    pred = tf.keras.layers.Dense(16, activation='softmax')(bert_outputs[:,0,:])\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=pred)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00002), metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:37:06.132034Z",
     "iopub.status.busy": "2023-05-31T16:37:06.131699Z",
     "iopub.status.idle": "2023-05-31T16:37:06.143183Z",
     "shell.execute_reply": "2023-05-31T16:37:06.141729Z",
     "shell.execute_reply.started": "2023-05-31T16:37:06.132007Z"
    }
   },
   "outputs": [],
   "source": [
    "# store the model\n",
    "def get_callbacks():\n",
    "    \n",
    "    best_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'best_model.h5',\n",
    "        verbose=1, \n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        save_best_only=True, \n",
    "        save_weights_only=True\n",
    "    )\n",
    "    \n",
    "    last_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'last_model.h5',\n",
    "        verbose=1, \n",
    "        save_best_only=False, \n",
    "        save_weights_only=True\n",
    "    )\n",
    "    \n",
    "    callbacks = [best_model , last_model]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:37:06.145797Z",
     "iopub.status.busy": "2023-05-31T16:37:06.145220Z",
     "iopub.status.idle": "2023-05-31T16:38:16.765045Z",
     "shell.execute_reply": "2023-05-31T16:38:16.763133Z",
     "shell.execute_reply.started": "2023-05-31T16:37:06.145758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d061682f5074eee80a09012d39148aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer)  [(None, 512)]            0         \n",
      "                                                                 \n",
      " tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  335141888\n",
      "                             lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             512, 1024),                         \n",
      "                              pooler_output=(None, 10            \n",
      "                             24),                                \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 1024)             0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                16400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335,158,288\n",
      "Trainable params: 335,158,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "use_tpu = True\n",
    "if use_tpu:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    model = create_model()\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:38:16.767543Z",
     "iopub.status.busy": "2023-05-31T16:38:16.766801Z",
     "iopub.status.idle": "2023-05-31T16:38:16.782456Z",
     "shell.execute_reply": "2023-05-31T16:38:16.780944Z",
     "shell.execute_reply.started": "2023-05-31T16:38:16.767509Z"
    }
   },
   "outputs": [],
   "source": [
    "types = np.unique(data.type.values)\n",
    "\n",
    "def get_type_index(string):\n",
    "    return list(types).index(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:38:16.783875Z",
     "iopub.status.busy": "2023-05-31T16:38:16.783548Z",
     "iopub.status.idle": "2023-05-31T16:38:16.838019Z",
     "shell.execute_reply": "2023-05-31T16:38:16.836710Z",
     "shell.execute_reply.started": "2023-05-31T16:38:16.783849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>INTP</td>\n",
       "      <td>phrases i never want to hear again a k a if yo...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>INTP</td>\n",
       "      <td>yeah  you say you primarily value people who ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>63915 i got my hair cut   d some people say t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>INFP</td>\n",
       "      <td>as far as i live in this world  i ve never bee...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>meh it s overplayed ya but still its good n...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>INFP</td>\n",
       "      <td>hey  it seems like you have a great foundatio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>dear istj mother    when i started my very fi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>INTP</td>\n",
       "      <td>oh entjs  how can you be scary and exciting a...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>hi  entp  and welcome to the forum  wink    f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>interesting  you ve gone from se dominant to n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  type_index\n",
       "984   INTP  phrases i never want to hear again a k a if yo...          11\n",
       "6706  INTP   yeah  you say you primarily value people who ...          11\n",
       "143   ENFP   63915 i got my hair cut   d some people say t...           1\n",
       "4844  INFP  as far as i live in this world  i ve never bee...           9\n",
       "4388  ISFP     meh it s overplayed ya but still its good n...          13\n",
       "...    ...                                                ...         ...\n",
       "4373  INFP   hey  it seems like you have a great foundatio...           9\n",
       "7891  INFJ   dear istj mother    when i started my very fi...           8\n",
       "4859  INTP   oh entjs  how can you be scary and exciting a...          11\n",
       "3264  ENFJ   hi  entp  and welcome to the forum  wink    f...           0\n",
       "2732  ENTP  interesting  you ve gone from se dominant to n...           3\n",
       "\n",
       "[6940 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['type_index'] = data['type'].apply(get_type_index)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:38:16.840543Z",
     "iopub.status.busy": "2023-05-31T16:38:16.840083Z",
     "iopub.status.idle": "2023-05-31T16:38:16.849024Z",
     "shell.execute_reply": "2023-05-31T16:38:16.847274Z",
     "shell.execute_reply.started": "2023-05-31T16:38:16.840501Z"
    }
   },
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "one_hot_labels = tf.keras.utils.to_categorical(train_data.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:38:16.851803Z",
     "iopub.status.busy": "2023-05-31T16:38:16.851368Z",
     "iopub.status.idle": "2023-05-31T16:50:43.525340Z",
     "shell.execute_reply": "2023-05-31T16:50:43.523846Z",
     "shell.execute_reply.started": "2023-05-31T16:38:16.851764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.3002 - accuracy: 0.2204 - f1_m: 0.0023 - precision_m: 0.0091 - recall_m: 0.0013\n",
      "Epoch 1: val_loss improved from inf to 2.12384, saving model to best_model.h5\n",
      "\n",
      "Epoch 1: saving model to last_model.h5\n",
      "82/82 [==============================] - 289s 2s/step - loss: 2.3002 - accuracy: 0.2204 - f1_m: 0.0023 - precision_m: 0.0091 - recall_m: 0.0013 - val_loss: 2.1238 - val_accuracy: 0.2974 - val_f1_m: 0.0236 - val_precision_m: 0.1027 - val_recall_m: 0.0134\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.8260 - accuracy: 0.4244 - f1_m: 0.2684 - precision_m: 0.5502 - recall_m: 0.1911\n",
      "Epoch 2: val_loss improved from 2.12384 to 1.56532, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: saving model to last_model.h5\n",
      "82/82 [==============================] - 56s 679ms/step - loss: 1.8260 - accuracy: 0.4244 - f1_m: 0.2684 - precision_m: 0.5502 - recall_m: 0.1911 - val_loss: 1.5653 - val_accuracy: 0.5533 - val_f1_m: 0.4931 - val_precision_m: 0.6974 - val_recall_m: 0.3979\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.3482 - accuracy: 0.5889 - f1_m: 0.5465 - precision_m: 0.7620 - recall_m: 0.4424\n",
      "Epoch 3: val_loss improved from 1.56532 to 1.29894, saving model to best_model.h5\n",
      "\n",
      "Epoch 3: saving model to last_model.h5\n",
      "82/82 [==============================] - 55s 669ms/step - loss: 1.3482 - accuracy: 0.5889 - f1_m: 0.5465 - precision_m: 0.7620 - recall_m: 0.4424 - val_loss: 1.2989 - val_accuracy: 0.6242 - val_f1_m: 0.6125 - val_precision_m: 0.7471 - val_recall_m: 0.5318\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0509 - accuracy: 0.6861 - f1_m: 0.6721 - precision_m: 0.8197 - recall_m: 0.5823\n",
      "Epoch 4: val_loss improved from 1.29894 to 1.25168, saving model to best_model.h5\n",
      "\n",
      "Epoch 4: saving model to last_model.h5\n",
      "82/82 [==============================] - 54s 664ms/step - loss: 1.0509 - accuracy: 0.6861 - f1_m: 0.6721 - precision_m: 0.8197 - recall_m: 0.5823 - val_loss: 1.2517 - val_accuracy: 0.6507 - val_f1_m: 0.6458 - val_precision_m: 0.7506 - val_recall_m: 0.5770\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8312 - accuracy: 0.7483 - f1_m: 0.7374 - precision_m: 0.8476 - recall_m: 0.6641\n",
      "Epoch 5: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 5: saving model to last_model.h5\n",
      "82/82 [==============================] - 50s 606ms/step - loss: 0.8312 - accuracy: 0.7483 - f1_m: 0.7374 - precision_m: 0.8476 - recall_m: 0.6641 - val_loss: 1.3699 - val_accuracy: 0.6438 - val_f1_m: 0.6422 - val_precision_m: 0.7235 - val_recall_m: 0.5865\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.8115 - f1_m: 0.8023 - precision_m: 0.8875 - recall_m: 0.7415\n",
      "Epoch 6: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 6: saving model to last_model.h5\n",
      "82/82 [==============================] - 49s 600ms/step - loss: 0.6285 - accuracy: 0.8115 - f1_m: 0.8023 - precision_m: 0.8875 - recall_m: 0.7415 - val_loss: 1.4082 - val_accuracy: 0.6409 - val_f1_m: 0.6450 - val_precision_m: 0.7133 - val_recall_m: 0.5960\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8665 - f1_m: 0.8585 - precision_m: 0.9211 - recall_m: 0.8107\n",
      "Epoch 7: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 7: saving model to last_model.h5\n",
      "82/82 [==============================] - 48s 584ms/step - loss: 0.4396 - accuracy: 0.8665 - f1_m: 0.8585 - precision_m: 0.9211 - recall_m: 0.8107 - val_loss: 1.5588 - val_accuracy: 0.6415 - val_f1_m: 0.6454 - val_precision_m: 0.6876 - val_recall_m: 0.6127\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9232 - f1_m: 0.9196 - precision_m: 0.9517 - recall_m: 0.8931\n",
      "Epoch 8: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 8: saving model to last_model.h5\n",
      "82/82 [==============================] - 48s 592ms/step - loss: 0.2658 - accuracy: 0.9232 - f1_m: 0.9196 - precision_m: 0.9517 - recall_m: 0.8931 - val_loss: 1.6843 - val_accuracy: 0.6346 - val_f1_m: 0.6412 - val_precision_m: 0.6899 - val_recall_m: 0.6049\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9575 - f1_m: 0.9526 - precision_m: 0.9711 - recall_m: 0.9369\n",
      "Epoch 9: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 9: saving model to last_model.h5\n",
      "82/82 [==============================] - 48s 586ms/step - loss: 0.1565 - accuracy: 0.9575 - f1_m: 0.9526 - precision_m: 0.9711 - recall_m: 0.9369 - val_loss: 1.8106 - val_accuracy: 0.6519 - val_f1_m: 0.6568 - val_precision_m: 0.6935 - val_recall_m: 0.6278\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9746 - f1_m: 0.9713 - precision_m: 0.9830 - recall_m: 0.9616\n",
      "Epoch 10: val_loss did not improve from 1.25168\n",
      "\n",
      "Epoch 10: saving model to last_model.h5\n",
      "82/82 [==============================] - 49s 596ms/step - loss: 0.1026 - accuracy: 0.9746 - f1_m: 0.9713 - precision_m: 0.9830 - recall_m: 0.9616 - val_loss: 1.9129 - val_accuracy: 0.6432 - val_f1_m: 0.6443 - val_precision_m: 0.6737 - val_recall_m: 0.6211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7db9bf0a4d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(train_input_ids), one_hot_labels, verbose = 1, epochs = NR_EPOCHS, batch_size = BATCH_SIZE,callbacks=get_callbacks(), validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T17:24:29.357712Z",
     "iopub.status.busy": "2023-05-31T17:24:29.357227Z",
     "iopub.status.idle": "2023-05-31T17:24:29.368867Z",
     "shell.execute_reply": "2023-05-31T17:24:29.367935Z",
     "shell.execute_reply.started": "2023-05-31T17:24:29.357677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data count：\n",
      "INFP    1476\n",
      "INFJ    1175\n",
      "INTP    1027\n",
      "INTJ     852\n",
      "ENTP     547\n",
      "ENFP     536\n",
      "ISTP     275\n",
      "ISFP     224\n",
      "ENTJ     196\n",
      "ISTJ     181\n",
      "ENFJ     147\n",
      "ISFJ     131\n",
      "ESTP      73\n",
      "ESFP      40\n",
      "ESTJ      31\n",
      "ESFJ      29\n",
      "Name: type, dtype: int64\n",
      "\n",
      "testing data count：\n",
      "INFP    356\n",
      "INFJ    295\n",
      "INTP    277\n",
      "INTJ    239\n",
      "ENFP    139\n",
      "ENTP    138\n",
      "ISTP     62\n",
      "ISFP     47\n",
      "ENFJ     43\n",
      "ISFJ     35\n",
      "ENTJ     35\n",
      "ISTJ     24\n",
      "ESTP     16\n",
      "ESFJ     13\n",
      "ESFP      8\n",
      "ESTJ      8\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"training data count：\")\n",
    "print(train_data['type'].value_counts())\n",
    "print()\n",
    "print(\"testing data count：\")\n",
    "print(test_data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run test and evaluate accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:50:43.559745Z",
     "iopub.status.busy": "2023-05-31T16:50:43.559283Z",
     "iopub.status.idle": "2023-05-31T16:50:43.607028Z",
     "shell.execute_reply": "2023-05-31T16:50:43.605762Z",
     "shell.execute_reply.started": "2023-05-31T16:50:43.559706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>dear isfj mother  i wish you were less of a w...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>to me  i think you guys may be over analyzing...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>nihm while nihm has her intj husband  i ve go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>INTP</td>\n",
       "      <td>i want 5 kids    an astro nuclear theoretical...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>i have the same thing as well  i ve noticed t...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>yes  i do it all the time  i just throw up my...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>hah   yes     that would be fantastic    d  d...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>the fact that she s an intj too pretty much e...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>to be perfectly honest  i don t know why you ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>thanks for the link  i think it certainly hel...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  type_index\n",
       "4587  ISFP   dear isfj mother  i wish you were less of a w...          13\n",
       "2786  INFJ   to me  i think you guys may be over analyzing...           8\n",
       "2813  ENFP   nihm while nihm has her intj husband  i ve go...           1\n",
       "3705  INTP   i want 5 kids    an astro nuclear theoretical...          11\n",
       "5957  ISFP   i have the same thing as well  i ve noticed t...          13\n",
       "...    ...                                                ...         ...\n",
       "418   INFJ   yes  i do it all the time  i just throw up my...           8\n",
       "6712  ISFP   hah   yes     that would be fantastic    d  d...          13\n",
       "6390  ISFP   the fact that she s an intj too pretty much e...          13\n",
       "4925  INFJ   to be perfectly honest  i don t know why you ...           8\n",
       "6868  INTJ   thanks for the link  i think it certainly hel...          10\n",
       "\n",
       "[1735 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['type_index'] = data['type'].apply(get_type_index)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:50:43.609404Z",
     "iopub.status.busy": "2023-05-31T16:50:43.608923Z",
     "iopub.status.idle": "2023-05-31T16:50:43.615540Z",
     "shell.execute_reply": "2023-05-31T16:50:43.614707Z",
     "shell.execute_reply.started": "2023-05-31T16:50:43.609362Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels = tf.keras.utils.to_categorical(test_data.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:50:43.617238Z",
     "iopub.status.busy": "2023-05-31T16:50:43.616936Z",
     "iopub.status.idle": "2023-05-31T16:50:57.439543Z",
     "shell.execute_reply": "2023-05-31T16:50:57.438489Z",
     "shell.execute_reply.started": "2023-05-31T16:50:43.617213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 14s 85ms/step - loss: 1.9184 - accuracy: 0.6317 - f1_m: 0.6357 - precision_m: 0.6725 - recall_m: 0.6108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9184226989746094,\n",
       " 0.6317002773284912,\n",
       " 0.6357413530349731,\n",
       " 0.6725378632545471,\n",
       " 0.6107954382896423]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(test_input_ids), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:50:57.441809Z",
     "iopub.status.busy": "2023-05-31T16:50:57.441462Z",
     "iopub.status.idle": "2023-05-31T16:50:57.449606Z",
     "shell.execute_reply": "2023-05-31T16:50:57.448368Z",
     "shell.execute_reply.started": "2023-05-31T16:50:57.441781Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = data['type'].unique()\n",
    "cols = cols.tolist()\n",
    "\n",
    "colnames = ['sentence']\n",
    "colnames = colnames+cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:50:57.457864Z",
     "iopub.status.busy": "2023-05-31T16:50:57.457257Z",
     "iopub.status.idle": "2023-05-31T16:51:14.443294Z",
     "shell.execute_reply": "2023-05-31T16:51:14.442058Z",
     "shell.execute_reply.started": "2023-05-31T16:50:57.457818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd00773d33a4ee39dea2e5795d8dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 17s 17s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_predict = pd.DataFrame(columns = colnames)\n",
    "sentence = [\"'I'm finding the lack of me in these posts very alarming.|||Sex can be boring if it's in the same position often. For example me and my girlfriend are currently in an environment where we have to creatively use cowgirl and missionary. There isn't enough...|||Giving new meaning to 'Game' theory.|||Hello *ENTP Grin*  That's all it takes. Than we converse and they do most of the flirting while I acknowledge their presence and return their words with smooth wordplay and more cheeky grins.|||This + Lack of Balance and Hand Eye Coordination.|||Real IQ test I score 127. Internet IQ tests are funny. I score 140s or higher.  Now, like the former responses of this thread I will mention that I don't believe in the IQ test. Before you banish...|||You know you're an ENTP when you vanish from a site for a year and a half, return, and find people are still commenting on your posts and liking your ideas/thoughts. You know you're an ENTP when you...|||http://img188.imageshack.us/img188/6422/6020d1f9da6944a6b71bbe6.jpg|||http://img.adultdvdtalk.com/813a0c6243814cab84c51|||I over think things sometimes. I go by the old Sherlock Holmes quote.  Perhaps, when a man has special knowledge and special powers like my  own, it rather encourages him to seek a complex...|||cheshirewolf.tumblr.com  So is I :D|||400,000+  post|||Not really; I've never thought of E/I or J/P as real functions.  I judge myself on what I use. I use Ne and Ti as my dominates. Fe for emotions and rarely Si. I also use Ni due to me strength...|||You know though. That was ingenious. After saying it I really want to try it and see what happens with me playing a first person shooter in the back while we drive around. I want to see the look on...|||out of all of them the rock paper one is the best. It makes me lol.  You guys are lucky :D I'm really high up on the tumblr system.|||So did you hear about that new first person shooter game? I've been rocking the hell out of the soundtrack on my auto sound equipment that will shake the heavens. We managed to put a couple PS3's in...|||No; The way he connected things was very Ne. Ne dominates are just as aware of their environments as Se dominates.  Example: Shawn Spencer or Patrick Jane; Both ENTPs.|||Well charlie I will be the first to admit I do get jealous like you do. I chalk it up to my 4w3 heart mixed with my dominate 7w8. 7s and 8s both like to be noticed. 4's like to be known (not the same...|||;D I'll upload the same clip with the mic away from my mouth. Than you won't hear anything.  Ninja Assassin style but with splatter.|||Tik Tok is a really great song. As long as you can mental block out the singer. I love the beat it makes me bounce.|||drop.io v1swck0  :D Mic really close to my mouth and smokin aces: assassins ball playing in the background.|||Sociable =/= extrovert; I'm an extrovert and I'm not sociable. :)|||Sherlock in the movie was an ENTP. Normally he's played as a EXTJ. In the books he's an ESTJ.  As I said. The movie looked good except for it being called sherlock holmes.|||http://i817.photobucket.com/albums/zz96/kamioo/Dirtywinch.png|||Oh, I never had fear of kissing a guy. I will kiss an animal too. So there was nothing to vanish. Just personal taste and me not liking it.  The guy I kissed didn't know me. It was one of those...|||Sounds pretty much like my area and what I'm going through right now trying to figure out which way I want to take my life. I want to do so many things. The biggest problem is that I know if I don't...|||;D I was operating under the impression that you were female. I never looked at your boxy. Okay, I help out my gay friends all the time and one of them has developed a little crush on me. I get red...|||T_T You just described me  and I'm living the worst nightmare. I'm trapped in one place with one one around. Only dull woods. If I was a serial killer this would be the perfect place but sadly I'm...|||TBH, and biased, sounds like a shadowed INFP. I think maybe he was hurt and turned ESTJ. I can tell because he has some of the typical INFP traits left over.|||*Checks list* I'm sorry. It seems that you have came at a bad time. We've already reached our quota of INFJs. However, being you're female and I like females I will make you a deal. I will kick one...|||I'm ANTP (Leaning toward E). I'm easy for both ENTPs and INTPs to identify with. :)|||I also imagine ENTP's interrogations would go a little bit like Jack's from 24 except more mechanical. Rigging up shock treatment equipment in an abandoned building out of an old car batty, jumper...|||It was a compliment :) Trust me. I'm just as psychopathic :D except I have emoticons. They're just weird ones. Like laughing when I get hurt or at people running themselves over with their lawn mower...|||http://i817.photobucket.com/albums/zz96/kamioo/Thunderstorm.pnghttp://i817.photobucket.com/albums/zz96/kamioo/Thunderstormbw.png http://i817.photobucket.com/albums/zz96/kamioo/Cosmicstorm.png|||No. It's like a theme for where I live and that is why I know it by heart.   http://www.youtube.com/watch?v=j5W73HaVQBg|||and I usual don't leave until the thing ends. But in the mean time. In between times. You work your thing. I'll work mine :D  ;D I'm the MBP; Pleasure to meet you.|||Damn, need to trust my instincts more I would have been closer I was going to say INFP.|||EXFP? Leaning toward S with the way she responded.  :D My friends, even my gay and lesbian ones, always come to me for advice.|||I bow to my entp masters ENTPs are so great. If it wasn't for ENTPs I wouldn't have been able to build what I'm building  Duck Duck  Duck  Shotgun|||What? Me? I never do that >.> <.<|||Because its hard to be sad about losing someone you like when you knew you were right and give yourself a big pat on the back because you're awesome and always correct.|||Oh, you don't have to tell me that most of them are stupid. I know this. That is why I play with them and it makes me laugh. :D As I'm going to take Neuropsychology and I have a few psychologist...|||:D I'm a Nightowl. I wake up between 6-7pm and stay awake till 10-11:30am.|||Personal opinion backed by theory would suggest that INTPs are the most socially difficult. While INTJs can be socially indifferent but they will also use social situations if the the need arises....|||Personal stocks that I have on my desktop that I've downloaded from random stock sites and stock photobuckets.|||I'll tell you when I open photoshop.  :) Glad you like it static.|||:D Thanks.|||http://i817.photobucket.com/albums/zz96/kamioo/Deathgrip.png http://i817.photobucket.com/albums/zz96/kamioo/Deathgripbw.png  Made for a friend. Several hours of work. I constructed every line by...|||:) Static: http://i817.photobucket.com/albums/zz96/kamioo/Statickitten.png  I'll have to get to your avatar later if one of my fellow teammates doesn't.|||Psychologist don't keep me around long enough to diagnosis me. I like to toy with them. What I have diagnosis myself with and had a few psychologist friends (+ a few other friends) tell me I have is...'\"]\n",
    "sentence_inputs = tokenize_sentences(sentence, tokenizer, MAX_LEN)\n",
    "sentence_inputs = pad_sequences(sentence_inputs, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "sentence_inputs\n",
    "\n",
    "prediction = model.predict(np.array(sentence_inputs))\n",
    "df_predict.loc[0,'sentence']=sentence\n",
    "df_predict.loc[0, cols] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:51:14.445500Z",
     "iopub.status.busy": "2023-05-31T16:51:14.445074Z",
     "iopub.status.idle": "2023-05-31T16:51:14.455668Z",
     "shell.execute_reply": "2023-05-31T16:51:14.454431Z",
     "shell.execute_reply.started": "2023-05-31T16:51:14.445460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1005,  1045,  1005,  1049,  4531,  1996,  3768,  1997,\n",
       "         2033,  1999,  2122,  8466,  2200,  8598,  2075,  1012,  1064,\n",
       "         1064,  1064,  3348,  2064,  2022, 11771,  2065,  2009,  1005,\n",
       "         1055,  1999,  1996,  2168,  2597,  2411,  1012,  2005,  2742,\n",
       "         2033,  1998,  2026,  6513,  2024,  2747,  1999,  2019,  4044,\n",
       "         2073,  2057,  2031,  2000,  5541,  2135,  2224, 11190, 15239,\n",
       "         1998,  8696,  1012,  2045,  3475,  1005,  1056,  2438,  1012,\n",
       "         1012,  1012,  1064,  1064,  1064,  3228,  2047,  3574,  2000,\n",
       "         1005,  2208,  1005,  3399,  1012,  1064,  1064,  1064,  7592,\n",
       "         1008,  4372, 25856,  5861,  1008,  2008,  1005,  1055,  2035,\n",
       "         2009,  3138,  1012,  2084,  2057, 23705,  1998,  2027,  2079,\n",
       "         2087,  1997,  1996, 20661,  2096,  1045, 13399,  2037,  3739,\n",
       "         1998,  2709,  2037,  2616,  2007,  5744,  2773, 13068,  1998,\n",
       "         2062,  5048,  2100, 20237,  1012,  1064,  1064,  1064,  2023,\n",
       "         1009,  3768,  1997,  5703,  1998,  2192,  3239, 12016,  1012,\n",
       "         1064,  1064,  1064,  2613, 26264,  3231,  1045,  3556, 13029,\n",
       "         1012,  4274, 26264,  5852,  2024,  6057,  1012,  1045,  3556,\n",
       "         8574,  2015,  2030,  3020,  1012,  2085,  1010,  2066,  1996,\n",
       "         2280, 10960,  1997,  2023, 11689,  1045,  2097,  5254,  2008,\n",
       "         1045,  2123,  1005,  1056,  2903,  1999,  1996, 26264,  3231,\n",
       "         1012,  2077,  2017,  7221,  4509,  1012,  1012,  1012,  1064,\n",
       "         1064,  1064,  2017,  2113,  2017,  1005,  2128,  2019,  4372,\n",
       "        25856,  2043,  2017, 25887,  2013,  1037,  2609,  2005,  1037,\n",
       "         2095,  1998,  1037,  2431,  1010,  2709,  1010,  1998,  2424,\n",
       "         2111,  2024,  2145, 15591,  2006,  2115,  8466,  1998, 16663,\n",
       "         2115,  4784,  1013,  4301,  1012,  2017,  2113,  2017,  1005,\n",
       "         2128,  2019,  4372, 25856,  2043,  2017,  1012,  1012,  1012,\n",
       "         1064,  1064,  1064,  8299,  1024,  1013,  1013, 10047,  2290,\n",
       "        15136,  2620,  1012,  4871,  3270,  3600,  1012,  2149,  1013,\n",
       "        10047,  2290, 15136,  2620,  1013,  4185, 19317,  1013,  3438,\n",
       "        11387,  2094,  2487,  2546,  2683,  2850,  2575,  2683, 22932,\n",
       "         2050,  2575,  2497,  2581,  2487, 19473,  2575,  1012, 16545,\n",
       "         2290,  1064,  1064,  1064,  8299,  1024,  1013,  1013, 10047,\n",
       "         2290,  1012,  4639,  2094, 16872, 28014,  1012,  4012,  1013,\n",
       "         6282,  2509,  2050,  2692,  2278,  2575, 18827, 22025, 16932,\n",
       "         3540,  2497,  2620,  2549,  2278, 22203,  1064,  1064,  1064,\n",
       "         1045,  2058,  2228,  2477,  2823,  1012,  1045,  2175,  2011,\n",
       "         1996,  2214, 20052,  9106, 14686,  1012,  3383,  1010,  2043,\n",
       "         1037,  2158,  2038,  2569,  3716,  1998,  2569,  4204,  2066,\n",
       "         2026,  2219,  1010,  2009,  2738, 16171,  2032,  2000,  6148,\n",
       "         1037,  3375,  1012,  1012,  1012,  1064,  1064,  1064, 13789,\n",
       "        12155, 10270,  1012, 10722, 14905, 20974,  1012,  4012,  2061,\n",
       "         2003,  1045,  1024,  1040,  1064,  1064,  1064,  4278,  1010,\n",
       "         2199,  1009,  2695,  1064,  1064,  1064,  2025,  2428,  1025,\n",
       "         1045,  1005,  2310,  2196,  2245,  1997,  1041,  1013,  1045,\n",
       "         2030,  1046,  1013,  1052,  2004,  2613,  4972,  1012,  1045,\n",
       "         3648,  2870,  2006,  2054,  1045,  2224,  1012,  1045,  2224,\n",
       "        11265,  1998, 14841,  2004,  2026, 29532,  1012, 10768,  2005,\n",
       "         6699,  1998,  6524,  9033,  1012,  1045,  2036,  2224,  9152,\n",
       "         2349,  2000,  2033,  3997,  1012,  1012,  1012,  1064,  1064,\n",
       "         1064,  2017,  2113,  2295,  1012,  2008,  2001, 13749, 18595,\n",
       "         3560,  1012,  2044,  3038,  2009,  1045,  2428,  2215,  2000,\n",
       "         3046,  2009,  1998,  2156,  2054,  6433,  2007,  2033,  2652,\n",
       "         1037,  2034,  2711, 13108,  1999,  1996,  2067,  2096,  2057,\n",
       "         3298,  2105,  1012,  1045,  2215,  2000,  2156,  1996,  2298,\n",
       "         2006,  1012,  1012,  1012,  1064,  1064,  1064,  2041,  1997,\n",
       "         2035,  1997,  2068,  1996,  2600,  3259,  2028,   102]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:51:14.457846Z",
     "iopub.status.busy": "2023-05-31T16:51:14.457438Z",
     "iopub.status.idle": "2023-05-31T16:51:14.481124Z",
     "shell.execute_reply": "2023-05-31T16:51:14.479931Z",
     "shell.execute_reply.started": "2023-05-31T16:51:14.457815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>INTP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESFJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['I'm finding the lack of me in these posts ve...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.992905</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      INFJ      ENTP  \\\n",
       "0  ['I'm finding the lack of me in these posts ve...  0.000014  0.000106   \n",
       "\n",
       "       INTP      INTJ     ENTJ      ENFJ      INFP      ENFP      ISFP  \\\n",
       "0  0.000146  0.992905  0.00002  0.000115  0.000031  0.000027  0.001765   \n",
       "\n",
       "       ISTP      ISFJ      ISTJ      ESTP      ESFP      ESTJ      ESFJ  \n",
       "0  0.000077  0.000002  0.004716  0.000021  0.000004  0.000021  0.000031  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:51:14.483455Z",
     "iopub.status.busy": "2023-05-31T16:51:14.482988Z",
     "iopub.status.idle": "2023-05-31T16:51:15.160998Z",
     "shell.execute_reply": "2023-05-31T16:51:15.159831Z",
     "shell.execute_reply.started": "2023-05-31T16:51:14.483414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d208715cc94ff6b3087e12ec884ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>INTP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESFJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['I'm finding the lack of me in these posts ve...</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.02873</td>\n",
       "      <td>0.105846</td>\n",
       "      <td>0.127425</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>0.018701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      INFJ      ENTP  \\\n",
       "0  ['I'm finding the lack of me in these posts ve...  0.007022  0.510682   \n",
       "\n",
       "       INTP      INTJ      ENTJ      ENFJ      INFP      ENFP     ISFP  \\\n",
       "0  0.000632  0.002771  0.003207  0.001989  0.002076  0.006848  0.02873   \n",
       "\n",
       "       ISTP      ISFJ      ISTJ      ESTP      ESFP      ESTJ      ESFJ  \n",
       "0  0.105846  0.127425  0.139296  0.002128  0.005511  0.037136  0.018701  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_inputs = tokenize_sentences(df_predict['sentence'], tokenizer, MAX_LEN)\n",
    "sentence_inputs = pad_sequences(sentence_inputs, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "prediction = model.predict(np.array(sentence_inputs))\n",
    "df_predict.loc[0, cols] = prediction\n",
    "\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I'm finding the lack of me in these posts very alarming.|||Sex can be boring if \n",
    "it's in the same position often. For example me and my girlfriend are currently \n",
    "in an environment where we have to creatively use cowgirl and missionary. There isn't \n",
    "enough...|||Giving new meaning to 'Game' theory.|||Hello *ENTP Grin*  That's all it takes. \n",
    "Than we converse and they do most of the flirting while I acknowledge their presence and \n",
    "return their words with smooth wordplay and more cheeky grins.|||This + Lack of Balance and Hand Eye Coordination.|||Real IQ test I score 127."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model to predict a single sentence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
